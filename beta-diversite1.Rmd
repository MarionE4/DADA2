---
title: "Bétâ-diversité"
author: "Marion MENEC"
date: "2023-11-01"
output: html_document
---
# Partie 1

```{r,eval=FALSE}
setwd("~/DADA2/course-material-main")
```


Charger les librairies utiles.
```{r}
library(phyloseq)
library(ggplot2)
library(dplyr)
devtools::load_all(path = "course-material-main/R")
```

```{r}
output_beta <- here::here("outputs", "beta_diversity")
if (!dir.exists(output_beta)) dir.create(output_beta, recursive = TRUE)
```

Charger les données.
```{r}
physeq <- readRDS(here::here("course-material-main",
                             "data",
                             "asv_table",
                             "phyloseq_object_alpha_beta_div.rds"))
```

# Partie 2
Normalisation des tables de données
Ici on le fait par raréfaction : nous sous-échantillons les reads de chaque échantillon sans remise à une "profondeur constante"
```{r}
rowSums(physeq@otu_table@.Data)
```

On va faire des tableaux de ces résultats et regarder les rangs d'abondance de nos reads.
```{r}
readsumsdf <- data.frame(nreads = sort(taxa_sums(physeq), decreasing = TRUE),
                        sorted = 1:ntaxa(physeq),
                        type = "OTUs")

tmp <- data.frame(nreads = sort(sample_sums(physeq), decreasing = TRUE), 
                  sorted = 1:nsamples(physeq),
                  type = "Samples")

readsumsdf <- rbind(readsumsdf, tmp)

head(readsumsdf)
```

```{r}
ggplot(readsumsdf, aes(x = sorted, y = nreads)) +
  geom_bar(stat = "identity") +
  ggtitle("Total number of reads") +
  scale_y_log10() +
  facet_wrap(~type, nrow = 1, scales = "free")
```

On veut s'assurer que l'effort des échantillonnages est le même pour tous les échantillons.
On défini la graine pour un échantillonnage aléatoire qui permet la reproductibilité.
```{r}
set.seed(10000)

min(rowSums(physeq@otu_table@.Data))
```

Le miminum de reads dans un échantillon est 837
Faisons l'échantillonnage aléatoire pour 800 reads par échantillon pour appliquer le processus à chaque échantillonnage pour avoir le même nombre partout (mettre tout le monde au même niveau, le plus bas)
```{r}
physeq_rar <- rarefy_even_depth(physeq, sample.size = 800)
rowSums(physeq_rar@otu_table@.Data)
```

```{r}
physeq
```

```{r}
physeq_rar
```

Les données du microbiome sont de composition car elles sont contraintes par la somme totale des lectures en raison de la profondeur de séquençage. Les abondances relatives des taxons sont interdépendantes en raison de cette contrainte, ce qui signifie qu'elles ne fournissent pas directement l'abondance réelle d'un taxon, mais plutôt des informations relatives par rapport à d'autres taxons dans le même échantillon. Pour analyser ces données, on utilise des transformations de rapports logarithmiques pour les placer dans un espace euclidien et appliquer des méthodes statistiques préférées. Il existe différents types de transformations de rapports logarithmiques, notamment additives, centrées et isométriques.

Faisons la transformation CLR (centered log-ratio)
```{r}
tmp <- zCompositions::cmultRepl(physeq@otu_table,
                                method = "CZM",
                                label = 0,
                                z.warning = 1)

physeq_clr_asv <- apply(tmp, 1, function(x) log(x) - mean(log(x)))
```

Tous le monde à la même enseigne : on centre et on passe en log.
```{r}
physeq_clr <- physeq
otu_table(physeq_clr) <- otu_table(t(physeq_clr_asv),
                                   taxa_are_rows = FALSE)
data.frame(physeq_clr@otu_table@.Data[1:5, 1:10])
```

# Partie 3

La première étape dans beaucoup de projets de microbiome, c'est de visualiser l'abondance relative des organismes à un rang taxonomique spécifique. La representation en arbre et les plots compilés sont deux façons de le faire
```{r}
physeq_phylum <- physeq_rar %>%
  tax_glom(taxrank = "Family") %>%                     # agglomerate at the Family level
  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
  psmelt() %>%                                         # Melt to long format
  filter(Abundance > 0.02) %>%                         # Filter out low abundance taxa
  arrange(Family)                                      # Sort data frame alphabetically by phylum

head(physeq_phylum)
```

Regarder la composition de la méta-communauté avec un arbre permet de détecter si certains taxa ne devraient pas être présents (contaminants) et d'observer si le taxa dominant correspond bien à l'habitat étudié.
```{r}
#pdf(file="treemap.pdf", wi = 7, he = 7)

treemap::treemap(physeq_phylum, index=c("Class", "Family"), vSize="Abundance", type="index",
        fontsize.labels=c(15,12),                
        fontcolor.labels=c("white","black"),# Color of labels
        fontface.labels=c(2,1),                  
        align.labels=list(
          c("center", "center"), 
          c("left", "bottom")), # Where to place labels in the rectangle?
        overlap.labels=0.5,
        inflate.labels=F, # If true, labels are bigger when rectangle is bigger.
        border.col=c("black","white"),#Color of the boders separating the taxonomic levels
        border.lwds=c(4,2),
        #palette = "Set3", # Select your color palette from the RColorBrewer presets or make your own.
        fontsize.title=12
)
```
size labels = donne la taille par niveau d'agrégation : taille du groupe, taille du sous-groupe, sous-sous-groupes...
fontface.lables = police des étiquettes, 1,2,3,4 pour normal, gras, italique, gras-italique...
overlap.labels = nombre compris entre 0 et 1 qui détermine la tolérance de chevauchement entre les étiquettes. 0 signifie que les étiquettes des niveaux inférieurs ne sont pas imprimées si les étiquettes des niveaux supérieurs se chevauchent, 1 signifie que les étiquettes sont toujours imprimées. Les valeurs intermédiaires, par exemple la valeur par défaut 0,5, signifie que les étiquettes de niveau inférieur sont imprimées si les autres étiquettes ne se chevauchent pas sur plus de 0,5 fois leur taille de zone.

```{r}
#dev.off()
```

Utilisation du package treemapify.
```{r}
tmp <- transform_sample_counts(physeq,function(x) {x/sum(x)} ) %>%
  psmelt() %>%
  group_by(Family, Class) %>%
  summarise(abundance = sum(Abundance)) %>%
  na.omit()

ggplot(tmp,aes(area=abundance,label=Family,fill=Class,subgroup=Class))+
  treemapify::geom_treemap()+
  treemapify::geom_treemap_subgroup_border() +
  treemapify::geom_treemap_subgroup_text(place = "centre",
                                         grow = T,
                                         alpha = 0.5,
                                         colour = "black",
                                         fontface = "italic",
                                         min.size = 0) +
  treemapify::geom_treemap_text(colour = "white",
                                place = "topleft",
                                reflow = TRUE)+
  theme(legend.position="none")
```


```{r}
ggsave(here::here(output_beta,"treemap_treemapify.pdf"))
```

Ici on peut observer que la méta-communauté est dominée par des clades typiquement marins comme le groupe marin AEGEAN dans les alphaprotéobactéries ou le clade SAR86 dans les gammaprotéobactéries. Donc tout va bien pour le moment ;)


```{r}
ggplot(physeq_phylum, aes(x = Sample, y = Abundance, fill = Family)) + 
  geom_bar(stat = "identity") +
  # facet_wrap(~Treatment, nrow=1, scales = "free_x") +
  ylab("Relative Abundance (Family > 2%)") +
  scale_y_continuous(expand = c(0,0)) + #remove the space below the 0 of the y axis in the graph
  ggtitle("Community composition") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 45, size = 10,
                                   hjust = 0.5, vjust = 0.8),
        axis.ticks.x = element_blank(),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank())  #remove minor-grid labels
```
Le blanc ce sont les inconnus, on n'a pas réussi à les attribuer à une famille.

```{r}
ggsave(here::here(output_beta, "asv_composition.pdf"))
```

Ici on peut déjà voir une différence de composition au niveau des familles avec un enrichissement dans les pseudoalteromonadaceae dans quelques échantillons et cyanobiaceae.
Il faut noter que nous sommes limités par notre habilité à discerner plus de 9-12 couleurs.


# Partie 4

Au fil des ans, les écologistes ont inventé de nombreuses façons de quantifier la dissimilarité entre des paires d'écosystèmes. Quatre composantes de la bêta-diversité des communautés d'espèces peuvent être évaluées à l'aide de différentes distances ou dissimilarités. Les distances ou dissimilarités de composition ne tiennent pas compte de l'abondance relative des taxons, mais uniquement de leur présence (détection) ou de leur absence, ce qui peut les rendre (trop) sensibles aux taxons rares, aux artefacts de séquençage et aux choix de filtrage de l'abondance. À l'inverse, les distances ou dissimilarités structurelles accordent (peut-être trop) d'importance aux taxons très abondants lors de la détermination des dissimilarités. Les distances ou dissimilarités phylogéniques tiennent compte de la parenté phylogénétique des taxons/séquences de vos échantillons lors du calcul de la dissimilarité, ce qui n'est pas le cas des distances ou dissimilarités taxonomiques.


Indice de jaccard binaire : présence / absence
```{r}
physeq_rar_jaccard <- phyloseq::distance(physeq_rar,
                                         method = "jaccard",
                                         binary = TRUE)

# trick to avoid negative egein values in PCoA
# it recreates what ade4::dist.binary() does
physeq_rar_jaccard <- sqrt(physeq_rar_jaccard)
```

Le package GUniFrac nécessite une arborescence enracinée comme données d'entrée. 
Pour vérifier si l'arbre est enraciné :
```{r}
ape::is.rooted(physeq_rar@phy_tree)
```

## Calculer les distances.

### Phylogénétique compositionnelle (Unifrac non pondéré)
UniFrac est un autre indice de bétâ-diversité. Il s'agit de l'intersection entre les échantillons, il pondère l'abondance relative des ASV par leur distance phylogénétique.
```{r}
unifracs <- GUniFrac::GUniFrac(physeq_rar@otu_table@.Data, physeq_rar@phy_tree, alpha=c(0, 0.5, 1))$unifracs
```

L'objet unifracs est une liste qui contient 5 matrices de distance qui correspondent à : weighted UniFrac (d_1), the unweighted UniFrac (d_UW), Variance adjusted UniFrac (d_VAW), GUniFrac with alpha = 0, GUniFrac with alpha = 0.5
```{r}
physeq_rar_du <- unifracs[, , "d_UW"]   # Unweighted UniFrac
```


### Taxonomique structurelle (Bray-Curtis)

```{r}
# physeq_rar_bray <- vegan::vegdist(physeq_rar@otu_table@.Data, method = "bray")

tmp <- transform_sample_counts(physeq,function(x) {x/sum(x)} )
physeq_rar_bray <- phyloseq::distance(tmp, method = "bray")
```


### Phylogénétique structurelle (Unifrac pondéré)

```{r}
physeq_rar_dw <- unifracs[, , "d_1"]   # Weighted UniFrac
```


## Visualisation

On peut calculer directement les distances, il y a 44 options de méthodes supportées explicitement dans le package phyloseq.
A travers chaque méthode de distance, on sauvegardera chaque plot et list et les résultats combinés dans un grahique.
```{r}
dist_methods <- unlist(distanceMethodList)
data.frame(position = seq_along(dist_methods),
           dist_methods)
```

```{r}
#Select the distances of interest
dist_methods <- dist_methods[c(1, 2, 10, 8)]
dist_methods
```

```{r}
#Loop through each distance method, save each plot to a list, called plist.
plist <- vector("list")

for(i in dist_methods){
  # Calculate distance matrix
  iDist <- phyloseq::distance(physeq_rar, method = i)
  # Calculate PCoA ordination
  iMDS <- ordinate(physeq_rar, "MDS", distance = iDist)
  ## Make plot. Don't carry over previous plot (if error, p will be blank)
  p <- NULL
  # Create plot, store as temp variable, p
  p <- plot_ordination(physeq_rar, iMDS, color= "Geo")
  # Add title to each plot
  p <- p + ggtitle(paste("MDS using distance method ", i, sep=""))
  # Save the graphic to list
  plist[[i]] = p 
}
```

Combiner les résultats : 
```{r}
df <- plyr::ldply(plist, function(x) x$data)
head(df)
```

Faire des ordinations avec différents indices.
```{r}
names(df)[1] <- "distance"

ggplot(df, aes(Axis.1, Axis.2, color = Geo)) +
  geom_point(size=3, alpha=0.5) +
  theme_bw() +
  facet_wrap(~distance, scales="free") +
  ggtitle("PCoA (MDS) on various distance metrics")
```

On peut observer qu'il y a une vraie séparation entre les échantillons du nord et du sud, à part les distances Weighted UniFrac qui tendent à donner plus de poids au ASV les plus abondantes qui sont aussi les plus fréquentes.


# Partie 5 : Clustering hiérarchique

## Classification ascendante hiérarchique (HAC)

Examiner les clusters d'échantillons sur des mesures de dis(similarités)
Les données de microbiome sont compositionelles, on va faire une classification ascendante hierarchique (HAC) des échantillons basée sur la distance Aitchison.
```{r}
#distance matrix calculation
physeq_clr_dist <- phyloseq::distance(physeq_clr, method = "euclidean")
```

Regardons les différence de clusters obtenus avec 4 critères d'aggrégation

```{r}
#Simple aggregation criterion
spe_single <- hclust(physeq_clr_dist, method = "single")

#Complete aggregation criterion
spe_complete <- hclust(physeq_clr_dist, method = "complete")

#Unweighted pair group method with arithmetic mean
spe_upgma <- hclust(physeq_clr_dist, method = "average")

#Ward criterion
spe_ward <- hclust(physeq_clr_dist, method = "ward.D")

par(mfrow = c(2, 2))
plot(spe_single, main = "single")
plot(spe_complete, main = "complete")
plot(spe_upgma, main = "UPGMA")
plot(spe_ward, main = "ward")

#ce n'est pas un test stat, c'est une procédure heuristique
```

Il ne faut pas oublier que le clustering est une procédure heuristique et non un test statistique. Les choix d'un coefficient d'association et d'une méthode de clustering influencent le résultat. Cela souligne l’importance de choisir une méthode cohérente avec les objectifs de l’analyse.


## Corrélation cophénétique

Une matrice cophénétique représente les distances cophénétiques entre toutes les paires d'objets. On peut calculer une corrélation de Pearson, appelée corrélation cophénétique, entre la matrice de dissimilarité originale et la matrice cophénétique. La méthode avec la corrélation cophénétique la plus élevée est considérée comme ayant produit le meilleur modèle de regroupement pour la matrice de distance.

Composons la matrice cophénétique et de corrélation de 4 résultats de clustering présents au-dessus.
```{r}
#Cophenetic correlation
spe_single_coph <- cophenetic(spe_single)
cor(physeq_clr_dist, spe_single_coph)
spe_complete_coph <- cophenetic(spe_complete)
cor(physeq_clr_dist, spe_complete_coph)
spe_upgma_coph <- cophenetic(spe_upgma)
cor(physeq_clr_dist, spe_upgma_coph)
spe_ward_coph <- cophenetic(spe_ward)
cor(physeq_clr_dist, spe_ward_coph)
```
Quel dendrogramme conserve la relation la plus proche avec la matrice de distance d'Aitchinson? Il s'agit du dendogramme de la méthode UPGMA car il a la corrélation la plus élevé.

Pour illustrer la relation entre la matrice de distance et un ensembles de matrices cophénétique obtenues de différentes façons, on peut réaliser un diagramme Shepard-like en traçant les distances originelles par rapport au distances cophénétique.
```{r}
plot_coph_cor <- function(cophenetic_distance, hclust_type){

  # first calculate the correlation between
  # the cophenetic distance and the observed distance
  cor_res <- round(cor(physeq_clr_dist, cophenetic_distance),3)

  # generate a scatter plot to visualise
  # the relationship
  plot(x = physeq_clr_dist,
     y = cophenetic_distance,
     xlab = "Aitchison distance",
     ylab = "Cophenetic distance",
     xlim = c(10, 35), ylim = c(10, 35),
     main = c(hclust_type, paste("Cophenetic correlation ", cor_res)))
  abline(0, 1)
}

par(mfrow=c(2,2))

plot_coph_cor(cophenetic_distance = spe_complete_coph,
              hclust_type = "Single linkage")

plot_coph_cor(cophenetic_distance = spe_complete_coph,
              hclust_type = "Complete linkage")

plot_coph_cor(cophenetic_distance = spe_upgma_coph,
              hclust_type = "Average linkage")

plot_coph_cor(cophenetic_distance = spe_ward_coph,
              hclust_type = "Ward linkage")
```

Il semblerait que la méthode UPGMA donne la représentation la plus représantative des distances originelles. Ce qui correspond à l'hypothèse plus haut.


## Recherche des clusters interprétables

Cela signifie qu'il faut décider à quel niveau faut-il couper le dendrogramme. De nombreux indices ont été publiés dans la littérature pour trouver le bon nombre de clusters dans un ensemble de données. Les valeurs du niveau de fusion d'un dendrogramme sont les valeurs de dissimilarité où se produit une fusion entre deux branches d'un dendrogramme. Tracer les valeurs du niveau de fusion peut aider à définir les niveaux de coupe. Traçons les valeurs du niveau de fusion pour le dendrogramme UPGMA.
```{r}
#Fusion level plot
par(mfrow = c(1, 1))

plot(x = spe_upgma$height,
     y = phyloseq::nsamples(physeq_clr):2,
     type = "S",
     main = "Fusion levels - Aitchison - Average",
     ylab = "k (number of cluster)",
     xlab = "h (node height)")

text(x = spe_upgma$height,
     y = phyloseq::nsamples(physeq_clr):2,
     labels = phyloseq::nsamples(physeq_clr):2,
     col = "red",
     cex = 0.8)
```
De droite à gauche, ce premier graphique montre des sauts claires après chaque fusion entre 2 groupes.
Utilisation du package NbClust pour déterminer le nombre exact de clusters dans le jeu de données.

```{r,eval=FALSE}
install.packages("NbClust", lib = ".")
library("NbClust", lib.loc = ".")
```


```{r}
nclust <- nb_clust_all(data = t(physeq_clr_asv), seed = 1000)
```

NbClust confirme qu'il y a bien 2 clusters. Retour au dendogramme pour le couper au bon endroit et pouvoir comparer les 2 clusters.
```{r}
k <- 2 # Number of groups given by the fusion level plot

#Cut the dendrogram
spe_upgma_clust <- cutree(tree = spe_upgma, k = k)
table(spe_upgma_clust)
```

```{r}
spe_upgma_clust2 <- data.frame(UPGMA_clusters = spe_upgma_clust)
```

```{r}
# Plot dendrogram with group labels
plot(spe_upgma,
     hang = -1,
     ylab = "Height",
     main="Aitchison distance - UPGMA")

rect.hclust(spe_upgma,
            k = k,
            border = 2:6,
            cluster = spe_upgma_clust)

legend("topright",
       paste("Cluster", 1:k),
       pch = 22,
       col = 2:(k + 1),
       bty = "n")
```

Il y a plusieurs manières de mesurer la robustesse d'un algorithme de clustering. Les 3 méthodes les plus communes sont celles de l'indice de Dunn, l'indice de Davis-Bouldin et l'indice de Silhoutte.
L'indice de Dunn est calculé comme le rapport de la plus petite distance inter-cluster à la plus grande distance intra-cluster. Un DI élevé signifie un meilleur regroupement puisque les observations de chaque cluster sont plus rapprochées, tandis que les clusters eux-mêmes sont plus éloignés les uns des autres. 
```{r}
cs <- fpc::cluster.stats(d = physeq_clr_dist,
                         clustering = spe_upgma_clust)

cs$dunn
```
DI est élevé. Cela indique que les échantillons ont un bons clustering.
Maintenant que 2 groupes ont été iddentifié, basé sur la composition de leur communauté microbienne, on va regarder quels clades ou ASVs les composent.

## Combinaison du clustering et de la Heatmap Z-score

La heatmap Z-score est normalisée et réduites. C'est la comparaison d'une valeur observée d'un échantillon à la moyenne de la population. Elle répond donc à la question : à quelle distance de la moyenne de la population se trouve un score pour un échantillon donné. Les scores sont donnés en écart-type (SD) par rapport à la moyenne de la population.

Sélection du top 30 ASV
```{r}
#Transform Row/normalized counts in percentage: transform_sample_counts
pourcentS <- phyloseq::transform_sample_counts(physeq_rar, function(x) x/sum(x) * 100)
#Selection of top 30 taxa 
mytop30 <- names(sort(phyloseq::taxa_sums(pourcentS), TRUE)[1:30])
#Extraction of taxa from the object pourcentS
selection30 <- phyloseq::prune_taxa(mytop30, pourcentS)
#See new object with only the top 30 ASV
selection30
```

Obtention du tableau des OTU et transformation Z-score
```{r}
#Retrieve abundance of ASV (otu_table) as table & put in data.prop variable
selection30_asv <- phyloseq::otu_table(selection30)
selection30_sample <- phyloseq::sample_data(selection30)

#Change the rownames
#See
rownames(selection30_asv)
```

```{r}
# rownames(data.prop)<-c("S11B_South5B","S1B_North1B","S2B_North2B","S2S_North2S","S3B_North3B","S3S_North3S","S4B_North4B","S4S_North4S","S5B_North5B","S5S_North5S","S6B_South1B","S6S_South1S","S7B_South2B","S7S_South2S","S8B_South3B","S8S_South3S","S9B_South4B","S9S_South4S")

sample_new_names <- paste(selection30_sample$SampName,
                          selection30_sample$Description,
                          sep = "_")

#Z-score transformation (with scale)
heat <- t(base::scale(selection30_asv))
#See
head(data.frame(heat))
```

Haetmap Z-score
```{r}
ComplexHeatmap::Heatmap(
  heat,
  row_names_gp = grid::gpar(fontsize = 6),
  cluster_columns = FALSE,
  heatmap_legend_param = list(direction = "vertical",
                              title = "Z-scores", 
                              grid_width = unit(0.5, "cm"),
                              legend_height = unit(3, "cm"))
)
```

Ajout de la taxonomy pour les noms d'ASV
```{r}
#get taxnomic table
taxon <- phyloseq::tax_table(selection30) |>
  as.data.frame()

#concatene ASV with Phylum & Family names
myname <- paste(rownames(taxon), taxon$Phylum, taxon$Family, sep="_")
#apply
colnames(selection30_asv) <- myname
```

Application à la heatmap
```{r}
#re-run Z-score to take into account the colnames change
heat <- t(scale(selection30_asv))

my_top_annotation <- ComplexHeatmap::anno_block(gp = grid::gpar(fill =c(3,4)),
                                               labels = c(1, 2),
                                               labels_gp = grid::gpar(col = "white",
                                                                      fontsize = 10))

ComplexHeatmap::Heatmap(
  heat,
  row_names_gp = grid::gpar(fontsize = 6),
  cluster_columns =TRUE,
  heatmap_legend_param = list(direction = "vertical",
   title ="Z-scores",
   grid_width = unit(0.5, "cm"),
   legend_height = unit(4, "cm")),
  top_annotation = ComplexHeatmap::HeatmapAnnotation(foo = my_top_annotation),
  column_km = 2,
  column_names_gp= grid::gpar(fontsize = 6)
  )
```

Ajout d'un boxplot de la distribution d'abondance des ASV dans les échantillons (Dans combien d'échantillon est présent cet ASV ?) 
```{r}
boxplot <- ComplexHeatmap::anno_boxplot(t(selection30_asv), 
                                        which = "row",
                                        gp = grid::gpar(fill = "turquoise3"))

my_boxplot_left_anno <- ComplexHeatmap::HeatmapAnnotation(Abund = boxplot,
                                                          which = "row",
                                                          width = unit(3, "cm"))

my_top_anno <- ComplexHeatmap::anno_block(gp = grid::gpar(fill = c(3, 6)),
                                          labels = c("South", "North"),
                                          labels_gp = grid::gpar(col = "white",
                                                                fontsize = 10))

my_top_anno <- ComplexHeatmap::HeatmapAnnotation(foo = my_top_anno)

ComplexHeatmap::Heatmap(
  heat,
  row_names_gp = grid::gpar(fontsize = 7),
  left_annotation = my_boxplot_left_anno, 
  heatmap_legend_param = list(direction = "vertical",
                              title ="Z-scores",
                              grid_width = unit(0.5, "cm"),
                              legend_height = unit(3, "cm")),
  top_annotation = my_top_anno,
  column_km = 2,
  cluster_columns = TRUE,
  column_dend_side = "bottom",
  column_names_gp = grid::gpar(fontsize = 7)
  )
```

Nous pouvons maintenant observer que les communautés microbiennes des échantillons du sud diffèrent dans leur composition microbienne de celles des échantillons du nord. L’effet significatif du traitement (Nord/Sud) reste à tester statistiquement. 
Cette différence dans la composition de la communauté est due à l’abondance différentielle apparente de nombreux ASV principaux du jeu de données. L’identification de biomarqueurs significatifs dans les échantillons du Nord et du Sud sera abordée plus tard.


# Partie 6 : Analyse de gradient indirect

Alors que l'analyse groupée recherche les discontinuités dans un ensemble de données, l'ordination extrait les principales tendances sous la forme d'axes continus. Elle est donc particulièrement bien adaptée pour analyser les données des communautés écologiques naturelles, généralement structurées en gradients. C'est pourquoi ce type d'analyse est appelé analyse de gradient. Le but des méthodes d'ordination est de représenter les données selon un nombre réduit d'axes orthogonaux, construits de telle manière qu'ils représentent, par ordre décroissant, les principales tendances des données. 
Il y a quatre types d’analyses largement utilisées en écologie : PCA, PCoA, NMDS. On va les utiliser.
Toutes ces méthodes sont descriptives : aucun test statistique n'est fourni pour évaluer la significativité des structures détectées. C'est le rôle de l'ordination contrainte ou de l'analyse des tests d'hypothèses que l'on verra plus tard.


## Analyse en composantes principales (PCA)

L'analyse en composantes principales (ACP) est une méthode permettant de résumer, dans un espace de faible dimension, la variance dans une dispersion multivariée de points. Ce faisant, il fournit un aperçu des relations linéaires entre les et les variables. Cela peut souvent constituer un bon point de départ dans l’analyse de données multivariées en permettant de noter les tendances, les regroupements, les variables clés et les valeurs aberrantes potentielles. Encore une fois, en raison de la nature compositionnelle des données sur le microbiome, nous utiliserons ici la distance d’Aitchinson. Il s'agit de la table ASV transformée CLR qui est utilisée directement et non de la matrice de distance d'Aitchinson. La fonction calculera une distance euclidienne sur cette table transformée CLR pour obtenir la matrice d'Aitchison. 


### Nombre de PC à conserver
Utilisation de scree plot (graphique d'éboulis) pour examiner la proportion total de variation expliquée par chaque PC.
```{r}
#prepare the ASV table to add taxonomy
tax_CLR <-  as.data.frame(tax_table(physeq_clr)) # get taxnomic table
#concatene ASV with Family & Genus names
ASVname <- paste(rownames(tax_CLR), tax_CLR$Family, tax_CLR$Genus,sep="_")
#apply 
rownames(physeq_clr_asv) <- ASVname
p <- PCAtools::pca(physeq_clr_asv,
                   metadata = data.frame(sample_data(physeq_clr)))
PCAtools::screeplot(p, axisLabSize = 18, titleLabSize = 22)
```

On voit que PC1 explique 31% de la variance et il y a ensuite un déclin graduel. Un scree plot montre juste la proportion accumulative de la variation expliquer. 
On doit maintenant déterminer le nombre optimal de PC à retenir.

```{r}
#Horn’s parallel analysis (Horn 1965) (Buja and Eyuboglu 1992)
horn <- PCAtools::parallelPCA(physeq_clr_asv)
horn$n
```
```{r}
#elbow method
elbow <- PCAtools::findElbowPoint(p$variance)
elbow
```
Les deux méyhodes indiquent qu'il ne faut retenir que les 2-3 premiers PC. 
Il est difficile de déterminer le nombre exacte de PC à garder mais en général on ne garde que les 2 premiers.

### Faire l'ordination
```{r}
#Plotting the PCA
PCAtools::biplot(
  p,
  lab = p$metadata$SampName,
  colby = "Geo",
  pointSize = 5,
  hline = 0, vline = 0,
  legendPosition = "right"
)
```
Chaque point est un échantillon, et les échantillons qui semblent plus rapprochés sont généralement plus similaires les uns aux autres que les échantillons plus éloignés. Ainsi en colorant les points par traitement on constate que les microbiotes du Nord sont souvent, mais pas toujours, très distincts des échantillons du Sud.


### Déterminer les variables qui déterminent la variation entre chaque PC

L’un des avantages de ne pas utiliser de matrice de distance est qu'on peut tracer les « chargements » de taxons sur les axes PCA, en utilisant l’argument showLoadings = TRUE. PCAtools vous permet de tracer le nombre de vecteurs de chargement de taxons souhaités en commençant par ceux ayant le plus de poids sur chaque PC. La longueur relative de chaque vecteur de chargement indique sa contribution à chaque axe PCA affiché et permet d'estimer approximativement quels échantillons contiendront le plus de ce taxon.

```{r}
PCAtools::biplot(
  p, 
  # loadings parameters
  showLoadings = TRUE,
  lengthLoadingsArrowsFactor = 1.5,
  sizeLoadingsNames = 3,
  colLoadingsNames = 'red4',
  ntopLoadings = 3,
  # other parameters
  lab = p$metadata$X.SampleID,
  colby = "Geo",
  hline = 0, vline = 0,
  legendPosition = "right"
)
```
Les ASV 7, 11 et 12 ont une contribution élevée au PC1 tandis que les ASV 38, 40 et 47 ont une contribution élevée au deuxième PC. Ces ASV appartiennent à seulement deux familles. Les échantillons du Sud semblent être enrichis en ASV7 tandis que les échantillons du Nord contiennent des abondances plus élevées d'ASV11 et 12. Les deux valeurs aberrantes de l'échantillon du Nord en haut du graphique sont caractérisées par une abondance plus élevée d'ASV 38, 40 et 47.


###Corréler les composants principaux avec les données environnementales

Une exploration plus approfondie des PC peut passer par des corrélations avec des données environnementales. Ici, on va va corréler les deux premiers PC avec des données environnementales.
```{r}
PCAtools::eigencorplot(
  p,
  components = PCAtools::getComponents(p, 1:horn$n),
  metavars = c('SiOH4','NO2','NO3','NH4','PO4',
              'NT','PT','Chla',"T", "S", "Sigma_t"),
  col = c('white', 'cornsilk1', 'gold',
          'forestgreen', 'darkgreen'),
  cexCorval = 1.2,
  fontCorval = 2,
  posLab = "all",
  rotLabX = 45,
  scale = TRUE,
  main = bquote(PC ~ Spearman ~ r^2 ~ environmental ~ correlates),
  plotRsquared = TRUE,
  corFUN = "spearman",
  corUSE = "pairwise.complete.obs",
  corMultipleTestCorrection = 'BH',
  signifSymbols = c("****", "***", "**", "*", ""),
  signifCutpoints = c(0, 0.0001, 0.001, 0.01, 0.05, 1)
)
```
La seule corrélation significative trouvée se situe entre le premier PC1 expliquant la séparation entre les échantillons Sud et Nord et la salinité. Ceci n'est pas intéressant mais la corrélation entre les variables ne signifie pas automatiquement que le changement d'une variable est la cause du changement des valeurs de l'autre variable. 
Nous vérifierons plus tard s’il existe une relation causale entre le gradient de salinité et la différence observée dans les communautés bactériennes du sud et du nord.


## Analyse des coordonnées principales (PCoA)

L'analyse des coordonnées principales (PCoA, également connue sous le nom de mise à l'échelle métrique multidimensionnelle, MDS) tente de représenter les distances entre les échantillons dans un espace euclidien de faible dimension. En particulier, il maximise la corrélation linéaire entre les distances dans la matrice de distance et les distances dans un espace de faible dimension (typiquement, 2 ou 3 axes sont sélectionnés). 
Comme toujours, le choix de la mesure de (dis)similarité est critique et doit être adapté aux données en question. Ici, on utilise la distance Bray-Curtis. Lorsque la métrique de distance est euclidienne, PCoA équivaut à l’analyse en composantes principales. L'interprétation des résultats est la même qu'avec PCA.


Préparation des données
```{r}
#BPCoA on Bray-Curtis dissimilarity
pcoa_asv <- ape::pcoa(physeq_rar_bray)
pcoa_coord <- pcoa_asv$vectors[, 1:2]

#Data frame for hull
hull <- data.frame("Axis.1" = pcoa_coord[, 1],
                   "Axis.2" = pcoa_coord[, 2],
                   "sample" = as.data.frame(sample_data(physeq_rar@sam_data)))


# North <- hull[hull$sample.Geo  == "North", ][chull(hull[hull$sample.Geo ==  "North", c("Axis.1", "Axis.2")]), ]  # hull values for North
# South <- hull[hull$sample.Geo == "South", ][chull(hull[hull$sample.Geo == 
#                                                          "South", c("Axis.1", "Axis.2")]), ]  # hull values for Jellyfishes  

# hull_data <- rbind(North, South)

#Vector of color for hulls
# color <- rep("#a65628", length(hull_data$sample.Geo))
# color[hull_data$sample.Geo == "North"] <- "#1919ff"
# hull_data <- cbind(hull_data, color)

hull_col <- c("#a65628","#1919ff")
names(hull_col) <- c("North","South")

hull_data <- hull %>%
  dplyr::group_by(sample.Geo) %>%
  dplyr::slice(chull(Axis.1,Axis.2)) %>%
  dplyr::mutate(color = hull_col[sample.Geo])

head(hull_data)
```


Plot du PCoA
```{r}
ggplot(data = hull, aes(x = Axis.1, y = Axis.2)) +
  geom_hline(yintercept = 0, colour = "lightgrey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "lightgrey", linetype = 2) +
  geom_polygon(data = hull_data,
               aes(group = sample.Geo,
                   fill = sample.Geo),
               alpha = 0.3) + # add the convex hulls)
  scale_fill_manual(values = c("Darkgrey", "#1919ff")) +
  geom_point(data = hull,
             aes(color = sample.Geo,
                 size = sample.S),
             alpha = 0.7) +
  scale_color_manual(values = c("Darkgrey", "#1919ff")) +
  xlab(paste("PCo1 (", round(pcoa_asv$values$Relative_eig[1]*100, 1), "%)")) +
  ylab(paste("PCo2 (", round(pcoa_asv$values$Relative_eig[2]*100, 1), "%)")) +
  theme_bw() +
  coord_equal() +
  theme(axis.title.x = element_text(size = 14), # remove x-axis labels
        axis.title.y = element_text(size = 14), # remove y-axis labels
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank(),  #remove minor-grid labels
        plot.background = element_blank())
```
Lordination des échantillons est similaire à celle observée avec PCA.
On a utilisé une matrice de dissimilarité sites/sites. Il n'y a pas de score d'espèce calculé mais c'est possible de le faire avce la fonction biplot.pcoa()(package ape).

Les inconvénients de PCoA sont nombreux notamment l'effet arch. Ces défauts proviennent en partie du fait que PCoA maximise une corrélation linéaire. La mise à l'échelle multidimensionnell non métrique (NMDS) corige ce problème en maximisant la corrélation de l'ordre de classement.


## Mise à l'échelle multidimensionnelle non métrique (NMDS)

NMDS tente de représenter la dissemblance par paire entre des objets dans un espace de faible dimension. Tout coefficient de dissimilarité ou mesure de distance peut être utilisé pour construire la matrice de distance utilisée comme entrée. NMDS est une approche basée sur le classement. Cela signifie que les données de distance d'origine sont remplacées par des classements. Bien que les informations sur l’ampleur des distances soient perdues, les méthodes basées sur les classements sont généralement plus robustes aux données qui n’ont pas de distribution identifiable.

NMDS est un algorithme itératif. Les routines NMDS commencent souvent par le placement aléatoire d'objets de données dans l'espace d'ordination. L'algorithme commence alors à affiner ce placement par un processus itératif, en essayant de trouver une ordination dans laquelle les distances ordonnées des objets correspondent étroitement à l'ordre des dissimilarités des objets dans la matrice de distance d'origine. La valeur de contrainte reflète dans quelle mesure l'ordination résume les distances observées entre les échantillons.

NMDS n’est pas une analyse propre. Cela a trois conséquences importantes :
- Il n’y a pas de résultat d’ordination unique
- Les axes de l'ordination ne sont pas ordonnés selon la variance qu'ils expliquent
- Le nombre de dimensions de l'espace de faible dimension doit être spécifié avant d'exécuter l'analyse.

Les axes ne sont pas commandés dans NMDS. vegan::metaMDS() fait automatiquement pivoter le résultat final du NMDS à l'aide de PCA pour faire correspondre l'axe 1 à la plus grande variance parmi les points d'échantillonnage du NMDS.

```{r}
#NMDS plot on Aitchison distance
physeq_clr_nmds <- vegan::metaMDS(physeq_clr_dist, k=2, trymax=100) #Aitchison distance
```

Un moyen utile d'évaluer la pertinence d'un résultat NMDS consiste à comparer, dans un diagramme de Shepard, les distances entre les objets du tracé d'ordination avec les distances d'origine.

```{r}
vegan::stressplot(physeq_clr_nmds)
```

Il existe un bon ajustement non métrique entre les dissimilarités observées (dans notre matrice de distance) et les distances dans l'espace d'ordination. De plus, le stress de notre résultat final était bon.

La valeur de contrainte peut être utilisée comme indicateur de la qualité de l'ajustement. Les valeurs de contrainte >0,2 sont généralement mauvaises et potentiellement non interprétables, tandis que les valeurs <0,1 sont bonnes et <0,05 sont excellentes, laissant peu de risque d'interprétation erronée.

On peut plot les résultats
```{r}
nmds_coord <- data.frame(physeq_clr_nmds$points)

#Data frame for hull
hull <- data.frame("Axis.1" = nmds_coord[,1],
                   "Axis.2" = nmds_coord[,2],
                   "sample" = as.data.frame(sample_data(physeq_clr@sam_data)))

# North <- hull[hull$sample.Geo  == "North", ][chull(hull[hull$sample.Geo == 
#                                                                 "North", c("Axis.1", "Axis.2")]), ]  # hull values for North
# South <- hull[hull$sample.Geo == "South", ][chull(hull[hull$sample.Geo == 
#                                                                "South", c("Axis.1", "Axis.2")]), ]  # hull values for Jellyfishes  

# hull_data <- rbind(North, South)

# #Vector of color for hulls
# color <- rep("#a65628", length(hull_data$sample.Geo))
# color[hull_data$sample.Geo == "North"] <- "#1919ff"
# hull_data <- cbind(hull_data, color)

hull_col <- c("#a65628","#1919ff")
names(hull_col) <- c("North","South")

hull_data <- hull %>%
  dplyr::group_by(sample.Geo) %>%
  dplyr::slice(chull(Axis.1,Axis.2)) %>%
  dplyr::mutate(color = hull_col[sample.Geo])

#pdf(file="NMDS_Aitchison.pdf", wi = 7, he = 7)
ggplot(hull,aes(x = Axis.1, y = Axis.2)) +
  geom_hline(yintercept = 0, colour = "lightgrey", linetype = 2) + 
  geom_vline(xintercept = 0, colour = "lightgrey", linetype = 2) +
  geom_polygon(data = hull_data,
               aes(group = sample.Geo,
                   fill = sample.Geo),
               alpha = 0.3) + # add the convex hulls)
  scale_fill_manual(values = c("Darkgrey", "#1919ff")) +
  geom_point(data = hull,
             aes(color = sample.Geo,
                 size = sample.S),
             alpha = 0.7) +
  scale_color_manual(values = c("Darkgrey", "#1919ff")) +
  geom_text(data = hull_data,
            x = -0, y = -9,
            label = paste("Stress =", round(physeq_clr_nmds$stress, 2)),
            colour = "Black",
            size = 5)  +
  xlab(paste("MDS1")) +
  ylab(paste("MDS2")) +
  theme_bw() +
  coord_equal() +
  theme(axis.title.x = element_text(size=14), # remove x-axis labels
        axis.title.y = element_text(size=14), # remove y-axis labels
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank(),  #remove minor-grid labels
        plot.background = element_blank())
```
On observe encore le même modèle d’ordonnancement des échantillons que dans le PCA et le PCoA. Il n’y a pas de scores d’espèces (même problème que celui rencontré avec PCoA). On peut contourner ce problème en utilisant la fonction wascores en donnant à metaMDS la matrice de communauté d'origine en entrée et en spécifiant la mesure de distance.


La question est la suivante : quelle variable environnementale est à l’origine des différences observées dans la composition des espèces ? De la même manière que nous l’avons fait avec PCA, nous pouvons corréler les variables environnementales avec nos axes d’ordination.
```{r}
# Correlation with environmental data
data.frame(names(hull))
```
```{r}
env <- hull[, 13:23]

# The function envfit will add the environmental variables as vectors to the ordination plot
ef <- vegan::envfit(physeq_clr_nmds, env, permu = 1000)
ef
```
```{r}
# The two last columns are of interest: the squared correlation coefficient and the associated p-value
# Plot the vectors of the significant correlations and interpret the plot
plot(physeq_clr_nmds, type = "t", display = "sites")
plot(ef, p.max = 0.05)
```
Là encore, on constate que la salinité est fortement corrélée au premier axe séparant les échantillons du Sud et du Nord. Dans une moindre mesure, de nouvelles variables environnementales liées aux conditions trophiques de l'habitat (NH4 et PT) ont été corrélées au deuxième axe du NMDS. La détection de ces nouvelles relations entre les communautés microbiennes et l'environnement peut être liée au fait que le NMDS est le mieux adapté pour détecter la réponse non linéaire des microbes aux gradients environnementaux.


# 7. Analyses des tests d'hypothèses

On a constaté une certaine ségrégation entre les échantillons du Nord et du Sud, suggérant des différences dans les communautés bactériennes selon le type d'échantillon. Bien que les analyses indirectes de gradient ou de classification soient des outils exploratoires de visualisation de données, on peut tester si les échantillons se regroupent au-delà de ce qui est attendu en utilisant des méthodes de test d'hypothèses telles que l'analyse multivariée de la variance avec permutation (PERMANOVA) et l'analyse des similarités de groupe (ANOSIM), multi-réponses. procédures de permutation (MRPP), test de Mantel (MANTEL) et plus récemment modèles multinomiaux de Dirichlet.


## Analyse multivariée de la variance avec permutation : PERmutational Multiple ANalysis Of VAriance (PERMANOVA)
PERMANOVA permet d'appliquer la puissante ANOVA à des ensembles de données écologiques multivariées. 
PERMANOVA est l’une des méthodes non paramétriques les plus utilisées pour adapter des modèles multivariés aux données du microbiome. Il s'agit d'une analyse multivariée de la variance basée sur des matrices de distance et des permutations. 

Évaluons maintenant si le groupe (Nord vs Sud) a un effet significatif sur la composition globale de la communauté bactérienne.
```{r}
#PERMANOVA
metadata <- data.frame(sample_data(physeq_clr))
results_permanova <- vegan::adonis2(physeq_clr_dist ~ Geo,
                                    data = metadata,
                                    perm = 1000)
results_permanova
```
On peut voir que le groupement Nord/Sud explique de manière significative 20% de la variance dans la matrice ASV d'Aitchison. En gors, les bactéries du Nord et du Sud diffère par leur composition. 
Le test d'ADONIS peut être perturbé par des différences de dispersion (ou d'étalement), c'est pourquoi nous souhaitons également vérifier cela.
```{r}
# Testing the assumption of similar multivariate spread among the groups (ie. analogous to variance homogeneity)
anova(vegan::betadisper(physeq_clr_dist, metadata$Geo))
```
Les groupes ont des dispersions significativement différentes. Les résultats de PERMANOVA ont peut -être été impactés par ça bien que PERMANOVA soit très robuste aux différences de dispersion des groupes. 
On peut également vérifier quels taxons contribuent le plus aux différences de communauté en utilisant l'ancienne fonction adonis() et la table ASV des décomptes transformés CLR.
```{r}
#Show coefficients for the top taxa separating the groups

permanova <- vegan::adonis(t(physeq_clr_asv) ~ Geo,
                            data = metadata,
                            permutations = 1000,
                            method = "euclidean")

coef <- coefficients(permanova)["Geo1",]

top.coef <- coef[rev(order(abs(coef)))[1:10]]

par(mar = c(3, 14, 2, 1))

barplot(sort(top.coef),
        horiz = TRUE,
        las = 1,
        main = "Top taxa",
        cex.names = 0.7)
```
On retrouve l'ASV 11, 12 et 7 qui avaient une forte contribution pour les axes PC, ainsi que d'autres ASV.

Test par rapport à la Salinité
```{r}
#Permanova on continuous variables
permanova_S <- vegan::adonis2(physeq_clr_dist ~ S,
                              data = metadata,
                              perm = 1000)
permanova_S
```

Test par rapport à NH4
```{r}
permanova_NH4 <- vegan::adonis2(physeq_clr_dist ~ NH4,
                                data = metadata,
                                perm = 1000)
permanova_NH4
```

Test par rapport à PT
```{r}
permanova_PT <- vegan::adonis2(physeq_clr_dist ~ PT,
                               data = metadata,
                               perm = 1000)
permanova_PT
```

Les résultats confirme que la salinité et dans une moindre mesure NH4 et PT sont des facteurs importants qui façonnent la communauté microbienne. 
Q'en est-il des autres variables ? On va construiree un model pour toutes les co-variables.
```{r}
#Inspecting co-variables
permanova_all <- vegan::adonis2(physeq_clr_dist ~ SiOH4 + NO2 + NO3 + NH4 + PO4 + NT + PT + Chla + T + S + Sigma_t,
                                by="margin",
                                data=metadata,
                                perm=1000)

permanova_all
```
Plus aucune variables n'est significative. Cela est lié à l'utilisation de la fonction adonis2() qui ne prend pas en compte l'odre dans lequel les variables sont rentrés et ne fait donc pas de biais là dessus.


Construction d'un modèle écologique utilisant toutes les informations disponibles (c’est-à-dire toutes les variables). On espère identifier chaque variable significative pour caractériser plus précisément les relations ayant une pertinence biologique. La corrélation excessive entre les variables explicatives, peut compliquer ou empêcher l'identification d'un ensemble optimal de variables explicatives pour un modèle statistique. Voyons quelles variables explicatives sont corrélées.
```{r}
# inpecting autocorrélation
# compute the correlation matrix
cor_metadadata <- cor(metadata[, 11:21], method = "spearman")

cor_mtest <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p_mat <- matrix(NA, n, n)
  diag(p_mat) <- 0
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], method = "spearman", ...)
      p_mat[i, j] <- p_mat[j, i] <- tmp$p.value
    }
  }
  colnames(p_mat) <- rownames(p_mat) <- colnames(mat)
  p_mat
}

# matrix of the p-value of the correlation
p_mat <- cor_mtest(metadata[, 11:21])

# Leave blank on no significant coefficient
corrplot::corrplot(cor_metadadata,
                   type = "upper",
                   order = "hclust",
                   p.mat = p_mat,
                   sig.level = 0.05,
                   insig = "blank")
```
On voit que beaucoup de variables explicatives sont corrélées. On va en enlever certaines d'entre elles. On S comme proxy de PO4, Sigma-t, NH4 et NO2. NO3 comme proxy de SiOH4. Chla en tant que mandataire de PT.
```{r}
permanova_cor_pars <- vegan::adonis2(physeq_clr_dist ~ S + NO3 + NT + Chla + T,
                                     by = "margin",
                                     data = metadata,
                                     perm = 1000)
permanova_cor_pars
```


Le modèle PERMANOVA mis à jour est amélioré par rapport à l'original. On voit que la salinité est encore une fois significativement liée à la variable de réponse. Cependant, le modèle avec uniquement la salinité est encore bien meilleur. Le message à retenir est que les véritables relations entre les variables seront masquées si les variables explicatives sont corrélées excessivement. Cela crée des problèmes dans la création de modèles qui entraînent des complications dans l'inférence du modèle. Prendre le temps supplémentaire pour évaluer la colinéarité est une première étape essentielle pour créer des modèles écologiques plus robustes.


## Analyse de similarité : ANalysis Of SIMilarity (ANOSIM)

ANOSIM teste la différence significative entre deux ou plusieurs classes d'objets sur la base de toute mesure de (dis)similarité. Il compare les rangs des distances entre les objets de différentes classes avec les rangs des distances des objets au sein des classes. La base de cette approche est similaire à la technique d’ordination NMDS.

```{r}
#ANOSIM
vegan::anosim(physeq_clr_dist, metadata$Geo, permutations = 1000)
```
À l’instar de PERMANOVA, le résultat d’ANOSIM indique un effet significatif de l’origine Nord ou Sud de l’échantillon sur les communautés bactériennes.

Une approche plus formelle du test d'hypothèses peut être réalisée en utilisant une analyse de redondance ou une analyse de correspondance canonique qui utilise directement les informations sur les champs de métadonnées lors de la génération des ordinations et de la réalisation des tests. Ces approches testent directement des hypothèses sur les variables environnementales.


# 8. Analyse de gradient direct (ordination canonique)

L'ordination simple (sans contrainte) analyse une matrice de données et révèle sa structure principale dans un graphique construit à partir d'un ensemble réduit d'axes orthogonaux. Il s'agit donc d'une forme d'analyse passive, et l'utilisateur interprète les résultats de l'ordination a posteriori. 
Au contraire, les analyses de gradient direct (appelées également ordination canonique) associent deux ou plusieurs ensembles de données dans le processus d'ordination lui-même. Par conséquent, si l’on souhaite extraire des structures d’un ensemble de données qui sont liées aux structures d’autres ensembles de données, et/ou tester formellement des hypothèses statistiques sur la signification de ces relations, l’ordination canonique est la voie à suivre. 
Ici, on va effectuer un RDA sur notre ensemble de données. 
Mais de nombreux autres types existent : analyse de redondance basée sur la distance (db-RDA), analyse des correspondances canoniques (CCA), analyse discriminante linéaire (LDA), analyse de corrélation canonique (CCorA), co-inertie. analyse (CoIA) et analyse factorielle multiple (MFA).


## Analyse redondante

### Exécuter la RDA

RDA est une méthode combinant régression et analyse en composantes principales (PCA). RDA calcule des axes qui sont des combinaisons linéaires des variables explicatives. En RDA, on peut vraiment dire que les axes expliquent ou modélisent (au sens statistique) la variation de la matrice dépendante.
```{r}
# RDA of the Aitchinson distance
# constrained by all the environmental variables
# contained in metadata
#
# Observe the shortcut formula
spe_rda <- vegan::rda(t(physeq_clr_asv) ~ .,
                      metadata[, 11:21])
head(summary(spe_rda))  # Scaling 2 (default)
```
Les variables environnementales incluses expliquent 70,44 % de la variation de la composition de la communauté bactérienne entre les sites. 
29,56 % de la variance est inexpliquée. Cependant, on verra que la proportion de variance expliquée est bien plus faible. 
Le R2 du résumé mesure la force de la relation canonique entre les variables de réponse (matrice Y, ASV) et les variables explicatives (matrice X) en calculant la proportion de la variation de Y expliquée par les variables de X. Cependant, ce R2 est biaisé. Nous calculons un R2 ajusté, qui mesure également la force de la relation entre Y et X, mais applique une correction du R2 pour prendre en compte le nombre de variables explicatives. C’est la statistique qui devrait être rapportée.
```{r}
# Unadjusted R^2 retrieved from the rda object
R2 <- vegan::RsquareAdj(spe_rda)$r.squared
R2
```
```{r}
# Adjusted R^2 retrieved from the rda object
R2adj <- vegan::RsquareAdj(spe_rda)$adj.r.squared
R2adj
```
En réalité, la proportion de variance expliquée est tombée à 16,25 %. Le résultat numérique montre que les deux premiers axes canoniques expliquent ensemble 35,1% de la variance totale des données, le premier axe expliquant à lui seul 25,9%. 
Ce sont cependant des valeurs non ajustées. Puisque R2 adj = 16,2 %, les pourcentages de valeurs propres contraintes accumulées montrent que le premier axe explique à lui seul 0,162 * 0,368 = 0,059 ou 5,9 % de variance. Les données écologiques étant généralement assez bruitées, il ne faut jamais s'attendre à obtenir une valeur de R2 très élevée. 
De plus, la première valeur propre non contrainte (PC1), le premier axe non contraint pour les résidus, est relativement élevée, ce qui signifie qu'elle affiche une structure résiduelle importante des données de réponse qui n'est pas expliquée par la mesure des paramètres environnementaux ici.


### Test de signification

L'interprétation de l'ordination contrainte doit être précédée d'un test de signification statistique. 
```{r}
# Global test of the RDA result
anova(spe_rda, step = 1000)
```
```{r}
# Tests of all canonical axes
anova(spe_rda, by = "axis", step = 1000)
```
Ici, on peut voir que le modèle complet est statistiquement non significatif (p = 0,08), et que tous les axes canoniques résultant de la RDA ne sont pas non plus statistiquement significatifs (p > 0,05). Ce modèle RDA n’est pas interprétable.
Pourquoi ? Parce que l'ajustement de R2 est trop important ?


### Sélection des variables

Parfois on veut réduire le nombre de variables explicatives pour différentes raisons (parcimonie, ensemble de données riches mais mauvaises hypothèses a priori et possibles dépendances linéaires fortes (corrélations) entre les variables explicatives du modèle RDA).

Une approche simple pour identifier la colinéarité entre les variables explicatives consiste à utiliser des facteurs d'inflation de variance (VIF). Les calculs VIF sont simples et facilement compréhensibles ; plus la valeur est élevée, plus la colinéarité est élevée. VIF mesure la proportion dans laquelle la variance d'un coefficient de régression est gonflée en présence d'autres variables explicatives. Les VIF supérieurs à 20 indiquent une forte colinéarité. Idéalement, les VIF supérieurs à 10 devraient au moins être examinés et évités si possible.
```{r}
# Variance inflation factors (VIF)
vegan::vif.cca(spe_rda)
```
Salinité, Température et Sigma.t ont des VIF très élevés qui confirment les colinéarités observées précédemment entre variables explicatives (voir la section PERMANOVA). Une réduction du nombre de variables explicatives est justifiée. Afin de simplifier ce modèle, on peut effectuer une sélection vers l'avant (ou vers l'arrière ou par étapes). Ces types de sélections nous aident à sélectionner des variables statistiquement importantes. 
Cependant, il est important de noter que la sélection écologique des variables est bien plus importante que la sélection de cette manière. Si une variable d’intérêt écologique n’est pas sélectionnée, cela ne signifie pas qu’elle doit être retirée de la RDA. Ici, on effectue une sélection avancée sur nos 11 variables environnementales. Pour ce faire, on utilise la fonction ordiR2step() :

```{r}
# Forward selection of explanatory variables using vegan's ordiR2step()
step_forward <- vegan::ordiR2step(vegan::rda(t(physeq_clr_asv) ~ 1,
                                             data = metadata[, 11:21]),
                                  scope = formula(spe_rda),
                                  direction = "forward",
                                  pstep = 1000)
```
Ici, on ajoute essentiellement une variable à la fois et la conservons si elle augmente considérablement le R2 ajusté du modèle. La sélection directe nous montre qu'un modèle avec uniquement la salinité a un ajustement R2 plus élevé qu'avec toutes les variables et explique 18,4 % de la variance. 
Calculons ce RDA, le plus parcimonieux, et vérifions sa signification.

```{r}
# Parsimonious RDA
spe_rda_pars <- vegan::rda(t(physeq_clr_asv) ~ S, data = metadata[, 11:21])
anova(spe_rda_pars, step = 1000)
```
```{r}
anova(spe_rda_pars, step = 1000, by = "axis")
```
```{r}
R2adj_pars <- vegan::RsquareAdj(spe_rda_pars)$adj.r.squared

# Compare variance inflation factors
vegan::vif.cca(spe_rda)
```
```{r}
vegan::vif.cca(spe_rda_pars)
```
Désormais, le modèle et le premier axe canonique résultant de la RDA sont statistiquement significatifs (p < 0,05). Le VIF de salinité n'est que de 1. 
Ce modèle RDA est interprétable. Traçons-le.


### RDA plot
```{r}
# Preparation of the data for the plot
#
# View analysis results
ii <- summary(spe_rda_pars)

# Depending on the drawing result
# the drawing data can be enlarged or
# reduced to a certain extent, as follows
sp <- as.data.frame(ii$species[, 1:2]) * 2
sp_top <- sp[order(abs(sp$RDA1), decreasing = TRUE), ][1:6, ]

st <- as.data.frame(ii$sites[, 1:2])
st <- merge(st,
      metadata["Geo"],
      by = "row.names")

yz <- t(as.data.frame(ii$biplot[, 1:2]))
row.names(yz) <- "Salinity"
yz <- as.data.frame(yz)

eigen_values <- format(100 *ii$cont[[1]][2,], digits=4)

#plot
ggplot() +
  geom_point(data = st, size = 4,
             aes(x = RDA1, y = PC1,
                 shape = Geo, fill = Geo)) +
  scale_shape_manual(values = c(21:25)) +
  geom_segment(data = sp_top,
               arrow = arrow(angle = 22.5,
                             length = unit(0.35, "cm"),
                             type = "closed"),
               linetype = 1, size = 0.6, colour = "red",
               aes(x = 0, y = 0, xend = RDA1, yend = PC1)) +
  ggrepel::geom_text_repel(data = sp_top,
                           aes(x = RDA1, y = PC1, label = row.names(sp_top))) +
  geom_segment(data = yz,
               arrow = arrow(angle = 22.5,
                             length = unit(0.35,"cm"),
                             type = "closed"),
               linetype = 1, size = 0.6, colour = "blue",
               aes(x = 0, y = 0, xend = RDA1, yend = PC1)) +
  ggrepel::geom_text_repel(data = yz, aes(RDA1, PC1, label=row.names(yz)))+
  labs(x = paste("RDA 1 (", eigen_values[1], "%)", sep = ""),
       y = paste("PC 1 (", eigen_values[2], "%)", sep = ""))+
  geom_hline(yintercept = 0,linetype = 3,size = 1) + 
  geom_vline(xintercept = 0,linetype = 3,size = 1)+
  guides(shape = guide_legend(title = NULL,
         color = "black"),
         fill = guide_legend(title = NULL))+
  theme_bw() +
  theme(panel.grid = element_blank())
```
L'un des aspects les plus puissants de la RDA est la visualisation simultanée de votre réponse et des variables explicatives (c'est-à-dire les espèces et les variables environnementales). 
De cette ordination, on peut vraiment dire maintenant que la salinité est le principal facteur environnemental mesuré qui façonne les communautés bactériennes. Parmi tous les ASV, certains sont davantage liés à ce gradient de salinité. C'est le cas des ASV 12 et 11 pour lesquels l'abondance augmente lorsque la salinité diminue et de l'ASV 7 qui présente le schéma inverse. 
Ces modèles d'abondance différentielle peuvent être explorés avec de nombreux types d'analyses, mais ce qui est vraiment puissant avec la RDA, c'est qu'on met en évidence des relations de gradient et non une différence d'abondance entre deux conditions. 
Cependant, une grande partie de la variance au sein de la communauté bactérienne reste inexpliquée. La variance des communautés d’espèces peut s’expliquer par des processus déterministes comme le tri des espèces (influence de l’environnement comme on l’a vu ici) mais aussi par des processus stochastiques comme la dispersion qui dépendent entre autres de la distance entre les communautés. Puisque nous disposons de ces informations, examinons un modèle très courant en écologie communautaire : le modèle de distance-décroissance.


## Régression multiple sur matrices de dissimilarité (MRM)

La diminution de la similarité des assemblages avec la distance spatiale peut s'expliquer par des mécanismes alternatifs : limitation de la dispersion et tri des espèces. Pour comprendre leurs contributions relatives, on compare la diminution de la similarité bactérienne avec la distance spatiale et, indépendamment, avec la distance environnementale.

On calcule d’abord la matrice de distance spatiale. 
Afin de calculer la distance kilométrique entre les points d'échantillonnage à partir de coordonnées géographiques, on a utilisé le package SpatialEpi et la fonction latlong2grid(). Ici, vous allez charger le résultat de cette fonction car il y a un conflit avec ce package et le package betapart qu'on utilise après.


```{r}
#library(SpatialEpi)
#ANFcoord <- read.table("Location_coordinates.txt", sep = "\t", row.names = 1, header = T)
#ANF_km <- latlong2grid(ANFcoord[,1:2])
#rownames(ANF_km) <- rownames(ANFcoord)

ANF_km <- readRDS("~/DADA2/course-material-main/data/beta_diversity/spatial_distance.rds")
ANF_km_dist <- dist(ANF_km)
```

Ensuite, la relation entre la similarité microbienne par paire et la distance spatiale est évaluée en ajustant une fonction exponentielle négative décrivant la diminution de la similarité microbienne avec la distance spatiale.
```{r}
#Calculate and add model to the plot

ANF_decay_exp <- betapart::decay.model(physeq_clr_dist/100,
                                       ANF_km_dist,
                                       y.type="dissim",
                                       model.type="exp",
                                       perm=100)

#Plot Distance decay relationships
plot(ANF_km_dist, physeq_clr_dist/100,
     ylim=c(0, max(physeq_clr_dist/100)),
     xlim=c(0, max(ANF_km_dist)),
     xlab = "Distance (km)", ylab = "Dissimilarity (CLR)")

betapart::plot.decay(ANF_decay_exp, col = "blue",
                     remove.dots = TRUE, add = TRUE)

legend("bottomright",
       paste("exp: (Beta =", round(ANF_decay_exp$second.parameter, 4),
             ", Rsqr =", round(ANF_decay_exp$pseudo.r.squared, 2),
             ", p =", round(ANF_decay_exp$p.value, 2)),
       fill = "blue")
```
Le modèle exponentiel négatif expliquait de manière significative la décroissance en similarité avec la distance spatiale (p < 0,01). 

Mais quelle est la contribution de la dispersion et du tri des espèces dans ce schéma ?  Pour cela on va décomposer la variance entre les matrices spatiale et environnementale.
```{r}
#Variance partitioning
#Microbiam matrix (response)
physeq_clr_dist_square <- phyloseq::distance(physeq_clr,
                                             method = "euclidean",
                                             diag = TRUE,
                                             upper = TRUE)

#Spatial matrix (explicative)
ANF_km_dist_square <- dist(ANF_km, diag = TRUE, upper = TRUE)

#environmental matrix (explicative)
envdata <- dist(metadata[,11:21], diag = TRUE, upper = TRUE)
```

```{r}
#Multiple regressions on Matrices (MRM) - attention les colonnes et lignes des matrices doivent correspondrent (pas besoin d'avoir les mêmes noms)

ecodist::MRM(physeq_clr_dist_square ~ envdata + ANF_km_dist_square, nperm=1000) # 0.366
```

```{r}
ecodist::MRM(physeq_clr_dist_square ~ envdata, nperm=1000) # 0.212
```

```{r}
ecodist::MRM(physeq_clr_dist_square ~ ANF_km_dist_square, nperm=1000) # 0.238
```

```{r}
modEvA::varPart(A = 0.212, B = 0.238, AB = 0.366,
                A.name = "Environmental",
                B.name = "Dispersal limitation")
```
En utilisant des matrices de régression multiple sur les distances (MRM), les variables spatiales et environnementales se sont révélées être des prédicteurs significatifs de la bêta-diversité et ont expliqué ensemble 36,7% de la variation de la dissimilarité des communautés microbiennes. 
Le partitionnement de la variance a ensuite été utilisé pour diviser la variation en composantes environnementales purement spatiales, purement environnementales et structurées spatialement. 
Avec 15,4%, la variation de dissimilarité expliquée par la composante purement spatiale était supérieure à la variation expliquée par la composante environnementale, indiquant que la dispersion est un processus important qui façonne nos communautés.


# 9. Analyse différentielle d'abondance (DAA)

L’objectif des tests d’abondance différentielle est d’identifier des taxons spécifiques associés à des variables de métadonnées d’intérêt. C'est une tâche difficile. Il s’agit également de l’un des domaines les plus controversés de l’analyse des données sur le microbiome. Cela est lié aux préoccupations selon lesquelles les approches de normalisation et de test n’ont généralement pas réussi à contrôler les taux de fausses découvertes.

Ils existent pleins d'outils pour réaliser une DAA.
Près et al. (2022) ont comparés les méthodes les plus populaires et on montré que ALDEx2 et ANCOM-BC produisent les résultats les plus cohérents d'un jeu de données à l'autre. Les résultats peuvent différés d'une méthode à l'autre car elles utilisent des approches différentes. Il est donc recommander d'utiliser plusieurs méthodes pour avoir une idée de la robsutesse et de la reproductibilité des résulatats.

Ici, application de 3 méthodes actuellement utilisées en écologie microbienne et comparaison des résultats entre les méthodes.


## Analyse discriminante linéaire Taille de l'effet (LEFse)

LEFse utilise d'abord le test de classement factoriel non paramétrique de Kruskal-Wallis (KW) pour détecter les caractéristiques présentant une abondance différentielle significative par rapport à la classe d'intérêt ; la cohérence biologique est ensuite étudiée à l'aide d'un ensemble de tests par paires parmi les sous-classes à l'aide du test de somme des rangs de Wilcoxon (non apparié). Dans une dernière étape, LEfSe utilise LDA pour estimer la taille de l'effet de chaque caractéristique différentiellement abondante.
```{r}
#LEFSE
mm_lefse <- microbiomeMarker::run_lefse(physeq, norm = "CPM",
                                        wilcoxon_cutoff = 0.01,
                                        group = "Geo",
                                        taxa_rank = "none",
                                        kw_cutoff = 0.01,
                                        multigrp_strat = TRUE,
                                        lda_cutoff = 4)

mm_lefse_table <- data.frame(mm_lefse@marker_table)
mm_lefse_table
```
```{r}
p_LDAsc <- microbiomeMarker::plot_ef_bar(mm_lefse)
y_labs <- ggplot_build(p_LDAsc)$layout$panel_params[[1]]$y$get_labels()
p_abd <- microbiomeMarker::plot_abundance(mm_lefse, group = "Geo") +
  scale_y_discrete(limits = y_labs)
gridExtra::grid.arrange(p_LDAsc, p_abd, nrow = 1)
```
LEFse identifie 12 biomarqueurs et parmi ceux là il y a les ASV 7, 11 et 12 qu'on a déjà croisé précédemment.


## Analyse différentielle des compositions de microbiomes avec correction des biais (ANCOM-BC)

La méthodologie ANCOM-BC suppose que l'échantillon observé est une fraction inconnue d'une unité de volume de l'écosystème et que la fraction d'échantillonnage varie d'un échantillon à l'autre. 
ANCOM-BC prend en compte la fraction d'échantillonnage en introduisant un terme de décalage spécifique à l'échantillon dans un cadre de régression linéaire, estimé à partir des données observées. Le terme de décalage sert de correction du biais, et le cadre de régression linéaire en échelle logarithmique est analogue à la transformation log-ratio pour traiter la compositionnalité des données du microbiome. De plus, cette méthode fournit des valeurs p et des intervalles de confiance pour chaque taxon. Il contrôle également le FDR et sa mise en œuvre est simple sur le plan informatique.
```{r}
#ancomBC
mm_ancombc <- run_ancombc_patched(
  physeq,
  group = "Geo",
  taxa_rank = "none",
  pvalue_cutoff = 0.001,
  p_adjust = "fdr"
)

mm_ancombc_table <- data.frame(mm_ancombc@marker_table)
mm_ancombc_table
```
```{r}
an_ef <- microbiomeMarker::plot_ef_bar(mm_ancombc)
y_labs <- ggplot_build(an_ef)$layout$panel_params[[1]]$y$get_labels()
an_abd <- microbiomeMarker::plot_abundance(mm_ancombc, group = "Geo") +
  scale_y_discrete(limits = y_labs)
gridExtra::grid.arrange(an_ef, an_abd, nrow = 1)
```
La fonction run_ancombc_patched n'est pas trouvé donc le code ne fonctionne pas.

ANCOM-BC devrait identifier 10 biomarqueurs et ils sont tous communs à ceux trouvé par l'analyse LEFse.


## Expression différentielle de type ANOVA (ALDEx2)

ALDEx2 estime la variation technique au sein de chaque échantillon par taxon en utilisant la distribution de Dirichlet. 
Il applique en outre la transformation de rapport logarithmique centrée (ou des transformations de rapport logarithmique étroitement liées). En fonction de la configuration expérimentale, il effectuera un test T de Welch et un test de Wilcoxon à deux échantillons ou un test ANOVA unidirectionnel et un test de Kruskal-Wallis. La procédure Benjamini-Hochberg est appliquée dans tous les cas pour corriger les tests multiples.

```{r}
mm_aldex <- microbiomeMarker::run_aldex(physeq, group = "Geo",
                                        norm = "CPM",
                                        taxa_rank = "none",
                                        p_adjust = "fdr")

mm_aldex_table <- data.frame(mm_aldex@marker_table)
mm_aldex_table
```

ALDEx2 est beaucoup plus strict et identifie un seul biomarqueur, ASV 27 qui a été identifié par les deux autres méthodes DAA. 
Les autres n’atteignent pas le seuil FDR utilisé ici ; bien qu’ils aient probablement des tailles d’effet «importantes». 

Souvent, si on envisage d'effectuer des tests DA, on exécuterai plusieurs modèles et se concentrerai sur l'intersection des OTU données par au moins deux méthodes. Ici, il s'agirait des 10 ASV identifié à l'ANCOM-BC.



